{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression\n",
    "\n",
    "Suppose we have a dataset consisting of $n$ observations, each of which has $p$ predictors / features.\n",
    "As training data, each of the $n$ examples has an outcome $y_i$. In the classic scenarios, $p$ is usually a fixed number and $ n \\gg p $. Whereas in modern cases, we usually have more features $p > n$.\n",
    "\n",
    "| obs |$X_{n\\times p}$| $Y_{n\\times 1}$ |\n",
    "|-----|-----------|-----|\n",
    "| 1   |    $x_1^T$  |$y_1$|\n",
    "| 2   |    $x_2^T$  |$y_2$|\n",
    "| ... |           |     |\n",
    "| n   |    $x_n^T$  |$y_n$|\n",
    "\n",
    "In the table, each row $x_i^T = ( x_{i1}, x_{i2} , \\ldots, x_{ip})$ is a data point and its corresponding outcome $y_i$.\n",
    "If we assume a linear relationship between the predictors and outcome with coefficients $\\beta = (\\beta_1, \\beta_2\\, \\ldots, \\beta_p)^T$, we have linear regression\n",
    "$$y_i = \\beta_1 x_{i1} + \\beta_2 x_{i2}  + \\cdots +  \\beta_p x_{ip} + \\epsilon_i = x_i^T \\beta + \\epsilon_i.$$\n",
    "\n",
    "To find $\\beta$, we minimize the residue sum of squares \n",
    "$$R(\\beta) = \\sum_{i=1}^{n} \\left(y_i - x_i^T\\beta\\right)^2,$$\n",
    "such that\n",
    "$$\\hat{\\beta} = \\arg\\min_{\\beta}R(\\beta).$$\n",
    "\n",
    "In matrix form, suppose data matrix $X_{n\\times p} = (X_1, X_2, \\ldots, X_p)$ is composed by $p$ columns in the table above, $Y$ is a vector which collects all the outcomes, we can write the residue as\n",
    "$$ R(\\beta) = \\left| Y - X\\beta \\right|^2.$$\n",
    "\n",
    "Solving the least squares means we want to find an approximated $\\hat{Y} = X\\hat{\\beta}$ in the space spanned by column vectors of $X$, i.e. $X_1, X_2, \\ldots, X_p$, so that the residue $R(\\hat{\\beta}) = Y^TY - \\hat{Y}^T \\hat{Y}$, the squared distance between $\\hat{Y}$ and $Y$, is minimized. We can solve a close form solution\n",
    "\n",
    "$$ \\hat{\\beta} = \\left(X^T X\\right)^{-1}X^T Y.$$\n",
    "\n",
    "Geometrically, $\\hat{Y}$ is the projection of $Y$ on the space spanned by $X_1, X_2, \\ldots, X_p$.\n",
    "\n",
    "<img src=\"figures/least-squares.pdf\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
